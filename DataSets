# -*- coding: utf-8 -*-
"""Animal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xAaauR9DCMt_5_MkmKCPh7dtxsMeG1kH
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import io

df = pd.read_csv(io.BytesIO(uploaded['Animal.csv']))
print(df)
print(df['Name'][0])

#X =  # here we have to define the columns that will be used as input
#Y =  # here we have to define the column that will be used as output
# split the dataset
#from sklearn.model_selection import train_test_split
#X_train, X_test, y_train, y_test = train_test_split(
#X, y, test_size=0.33, random_state=42)



import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
X = df[['Breed', 'Color', 'Age upon Intake']]
y = df['Sex upon Intake']

# Define preprocessing (one-hot encoding for all features)
categorical_features = ['Breed', 'Color', 'Age upon Intake']
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])
clf = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier(random_state=42))
])

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = clf.predict(X_test)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
X = df[['Breed', 'Color', 'Age upon Intake']]
y = df['Sex upon Intake']

# Define preprocessing (one-hot encoding for all features)
categorical_features = ['Breed', 'Color', 'Age upon Intake']
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ])
clf = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(random_state=42))
])

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the model
clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = clf.predict(X_test)

print(y_test)

print(y_pred)

print(y_test)

sum = 0
accuracy_score(y_test, y_pred)
  if (y_pred[i]==y_test[i]):
    sum = sum + 1
print(sum)

print(type(y_test))

from sklearn.metrics import accuracy_score


print(y_pred[0])

print(y_test[0])

MLPClassifier

accuracy_score(y_test, y_pred)

y_test

y_pred

y_true = y_test.values.ravel()


print(f"Accuracy = {acc:.3f}")

import numpy as np

# assume y_test is a one‐column DataFrame or Series
y_true = y_test.values.ravel()     # shape (n,)
y_pred = np.array(y_pred, dtype=object)

# Option A: drop any missing ground‐truth
mask = pd.notnull(y_true)
y_true_clean = y_true[mask]
y_pred_clean = y_pred[mask]

accuracy = np.mean(y_true_clean == y_pred_clean)
print(f"Accuracy = {accuracy:.3f}")
